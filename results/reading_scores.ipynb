{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb703ebd-f529-4e0a-b997-d04313997d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5f5dd5a5-f848-4456-898b-4f68b8d45597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>original_response</th>\n",
       "      <th>llama_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes, here I am :)</td>\n",
       "      <td>Hi there - good to speak to you!</td>\n",
       "      <td>Yes, here I am :). I'm so glad you're here! *h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm from Spain, from Tenerife. I came back hom...</td>\n",
       "      <td>OK yes I can imagine! It's pretty cold here in...</td>\n",
       "      <td>I'm from Spain, from Tenerife. I came back hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At the moment I'm not working so I have a lot ...</td>\n",
       "      <td>What's your normal work?</td>\n",
       "      <td>At the moment I'm not working so I have a lot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>About traveling to the UK, I don't go often. I...</td>\n",
       "      <td>Ah right - yes I thought you seemed very fluen...</td>\n",
       "      <td>About traveling to the UK, I don't go often. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In my last job I worked as a careers advisor (...</td>\n",
       "      <td>It's careers!</td>\n",
       "      <td>In my last job I worked as a careers advisor (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0                                  Yes, here I am :)   \n",
       "1  I'm from Spain, from Tenerife. I came back hom...   \n",
       "2  At the moment I'm not working so I have a lot ...   \n",
       "3  About traveling to the UK, I don't go often. I...   \n",
       "4  In my last job I worked as a careers advisor (...   \n",
       "\n",
       "                                   original_response  \\\n",
       "0                   Hi there - good to speak to you!   \n",
       "1  OK yes I can imagine! It's pretty cold here in...   \n",
       "2                           What's your normal work?   \n",
       "3  Ah right - yes I thought you seemed very fluen...   \n",
       "4                                      It's careers!   \n",
       "\n",
       "                                      llama_response  \n",
       "0  Yes, here I am :). I'm so glad you're here! *h...  \n",
       "1  I'm from Spain, from Tenerife. I came back hom...  \n",
       "2  At the moment I'm not working so I have a lot ...  \n",
       "3  About traveling to the UK, I don't go often. I...  \n",
       "4  In my last job I worked as a careers advisor (...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s = pd.read_csv('processed_llama2.csv')\n",
    "df = df_s.replace('', None).dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "72fdd67b-dfcb-49bd-8771-5cd59d54869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    word = word.lower()\n",
    "    vowels = \"aeiouy\"\n",
    "    syllable_count = 0\n",
    "    if word[0] in vowels:\n",
    "        syllable_count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            syllable_count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        syllable_count -= 1\n",
    "    if syllable_count == 0:\n",
    "        syllable_count = 1\n",
    "    return syllable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6b5490ed-f2f7-427a-ae57-f77e2c9b537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flesch_reading_ease(text):\n",
    "    # Split the text into sentences and words\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentences = [s for s in sentences if s]  # Remove empty strings\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    words = re.findall(r'\\w+', text)\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Calculate syllables\n",
    "    syllable_count = sum(count_syllables(word) for word in words)\n",
    "    \n",
    "    # Calculate ASL (Average Sentence Length) and ASW (Average Syllables per Word)\n",
    "    ASL = num_words / num_sentences if num_sentences > 0 else 0\n",
    "    ASW = syllable_count / num_words if num_words > 0 else 0\n",
    "    \n",
    "    # Calculate Flesch Reading Ease score\n",
    "    flesch_score = 206.835 - (1.015 * ASL) - (84.6 * ASW)\n",
    "    return flesch_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17b2f4b9-a434-4618-88e0-9133e478776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Flesch Reading Ease Score (Original): 85.4575709460931\n",
      "Average Flesch Reading Ease Score (Llama): 77.0865226955559\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to calculate the Flesch Reading Ease score for each row\n",
    "df['FleschReadingEase_Original'] = df['original_response'].apply(calculate_flesch_reading_ease)\n",
    "df['FleschReadingEase_Llama'] = df['llama_response'].apply(calculate_flesch_reading_ease)\n",
    "\n",
    "# Calculate the average Flesch Reading Ease score across the column\n",
    "average_score_og = df['FleschReadingEase_Original'].mean()\n",
    "average_score_ll = df['FleschReadingEase_Llama'].mean()\n",
    "\n",
    "# Display the DataFrame with the Flesch Reading Ease scores and print the average score\n",
    "#print(df)\n",
    "print(f\"Average Flesch Reading Ease Score (Original): {average_score_og}\")\n",
    "print(f\"Average Flesch Reading Ease Score (Llama): {average_score_ll}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5efb1df-7987-4887-b280-41e1b3bf389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "# Average Flesch Reading Ease Score (Original): 85.51828929776485\n",
    "# Average Flesch Reading Ease Score (Llama): 77.88151880974976\n",
    "\n",
    "#dev\n",
    "# Average Flesch Reading Ease Score (Original): 83.03879332077877\n",
    "# Average Flesch Reading Ease Score (Llama): 87.60023413654709\n",
    "\n",
    "#test\n",
    "# Average Flesch Reading Ease Score (Original): 90.55622109822762\n",
    "# Average Flesch Reading Ease Score (Llama): 83.12165369634366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a245201-6b7a-413f-b7a7-f788a3bc215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original grade mapping ('6th grade', 'fairly easy', '11-12')\n",
      "Llama grade mapping ('7th grade', 'easy', '12-13')\n"
     ]
    }
   ],
   "source": [
    "def map_fkre_to_grade(fkre_score):\n",
    "    if 90 <= fkre_score <= 100:\n",
    "        return \"5th grade\", \"very easy\", \"11\"\n",
    "    elif 80 <= fkre_score < 90:\n",
    "        return \"6th grade\", \"fairly easy\", \"11-12\"\n",
    "    elif 70 <= fkre_score < 80:\n",
    "        return \"7th grade\", \"easy\", \"12-13\"\n",
    "    elif 60 <= fkre_score < 70:\n",
    "        return \"8th–9th grade\", \"medium\", \"13-15\"\n",
    "    elif 50 <= fkre_score < 60:\n",
    "        return \"10th–12th grade\", \"difficult\", \"15-18\"\n",
    "    elif 30 <= fkre_score < 50:\n",
    "        return \"College\", \"fairly difficult\", \"18-19\"\n",
    "    elif 0 <= fkre_score < 30:\n",
    "        return \"College graduate\", \"very difficult\", \"22-23\"\n",
    "    else:\n",
    "        return \"Unknown\", \"Unknown\", \"Unknown\"\n",
    "\n",
    "og_grade = map_fkre_to_grade(average_score_og)\n",
    "ll_grade = map_fkre_to_grade(average_score_ll)\n",
    "print(f\"Original grade mapping {og_grade}\")\n",
    "print(f\"Llama grade mapping {ll_grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0e2cede-51a9-4ac6-8a31-0c5404c39b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.04323106598821415\n"
     ]
    }
   ],
   "source": [
    "smooth_fn = SmoothingFunction().method1\n",
    "\n",
    "# Function to calculate BLEU score with smoothing\n",
    "def calculate_bleu(reference, generated):\n",
    "    reference_tokens = [reference.split()]  # BLEU expects a list of references\n",
    "    generated_tokens = generated.split()\n",
    "    return sentence_bleu(reference_tokens, generated_tokens, smoothing_function=smooth_fn)\n",
    "\n",
    "# Calculate BLEU score for each row\n",
    "df['BLEU_Score'] = df.apply(lambda row: calculate_bleu(row['original_response'], row['llama_response']), axis=1)\n",
    "\n",
    "# Calculate the average BLEU score\n",
    "average_bleu_score = df['BLEU_Score'].mean()\n",
    "\n",
    "# Display the DataFrame with BLEU scores and the average score\n",
    "#print(df)\n",
    "print(f\"Average BLEU Score: {average_bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ba7dbc1-02f5-43c9-b148-093f45dca6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7091"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace870c-3649-4137-bcc9-58c6e6a239cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to calculate blue score\n",
    "#avg number of rows is 159.5076923076923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6230e7f-dc4e-451a-acb8-a8684f6a921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40a55c0a-ae05-47cc-8e6d-9c8e4d8f22d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.16277312423853718\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(reference, generated):\n",
    "    # Fit and transform both texts into TF-IDF vectors\n",
    "    tfidf_matrix = vectorizer.fit_transform([reference, generated])\n",
    "    # Calculate the cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Calculate cosine similarity for each row\n",
    "df['Cosine_Similarity'] = df.apply(lambda row: calculate_cosine_similarity(row['original_response'], row['llama_response']), axis=1)\n",
    "\n",
    "# Calculate the average cosine similarity\n",
    "average_cosine_similarity = df['Cosine_Similarity'].mean()\n",
    "\n",
    "# Display the DataFrame with cosine similarities and the average score\n",
    "#print(df)\n",
    "print(f\"Average Cosine Similarity: {average_cosine_similarity}\")\n",
    "#Average Cosine Similarity: 0.18851960845236906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09baf356-51d1-4121-9cbf-60764356a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Type-Token Ratio: 0.9721520872870951\n",
      "Average Type-Token Ratio: 0.7950575514405909\n"
     ]
    }
   ],
   "source": [
    "def calculate_ttr(text):\n",
    "    words = text.split()  # Split text into words (tokens)\n",
    "    unique_words = set(words)  # Get unique words (types)\n",
    "    ttr = len(unique_words) / len(words) if words else 0  # Calculate TTR, avoid division by zero\n",
    "    return ttr\n",
    "\n",
    "# Apply the TTR calculation to each row in the DataFrame\n",
    "df['Type_Token_Ratio_og'] = df['original_response'].apply(calculate_ttr)\n",
    "df['Type_Token_Ratio_ll'] = df['llama_response'].apply(calculate_ttr)\n",
    "\n",
    "# Calculate the average TTR across all rows (optional)\n",
    "average_ttr_og = df['Type_Token_Ratio_og'].mean()\n",
    "average_ttr_ll = df['Type_Token_Ratio_ll'].mean()\n",
    "\n",
    "# Display the DataFrame with TTR and the average TTR\n",
    "#print(df)\n",
    "print(f\"Average Type-Token Ratio: {average_ttr_og}\")\n",
    "print(f\"Average Type-Token Ratio: {average_ttr_ll}\")\n",
    "#Average Type-Token Ratio: 0.9605937843118938\n",
    "#Average Type-Token Ratio: 0.7989883610452374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aba8499-ca65-46dd-9477-894b1f804ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words: 14.568627450980392\n"
     ]
    }
   ],
   "source": [
    "average_words = df['original_response'].apply(lambda x: len(str(x).split())).mean()\n",
    "\n",
    "print(f\"Average number of words: {average_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a436d36a-ffb6-457e-aac0-bcdc7484b4c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_response\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "print(df['original_response'][0].apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d490ebc-2927-4eb8-a79f-acd9100e5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "d = df['original_response'][0]\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19f267e8-e90b-4ac5-99c1-c667339b0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16808aa6-b5d9-4f22-a71f-acc614c07e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11204"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "494adf59-0fae-45b2-ab33-f10c46176044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.truncate(after=1010)\n",
    "df.to_csv('trunc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49da18b-1403-4a62-8fd8-511eea4c4665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
