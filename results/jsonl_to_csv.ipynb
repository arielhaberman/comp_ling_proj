{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccb01e9-731b-43b0-97f8-d541dfb63d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariel\\Documents\\second_year\\comp_ling\\comp_ling_proj\\results\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import jsonlines\n",
    "import json\n",
    "print(os.getcwd())\n",
    "import regex as re\n",
    "import glob\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1919ad58-a05c-4a61-8788-649eab6c6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'C:/Users/ariel/Documents/second_year/comp_ling/comp_ling_proj/results/test/teacherstudentchat00014_dpo.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a2da5a-eef2-475d-9da1-0b110fc17473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed teacherstudentchat00014_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00025_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00044_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00061_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00063_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00065_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00066_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00067_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00068_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00072_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00074_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00086_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00088_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00089_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00100_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00109_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00111_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00112_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00118_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00125_dpo.jsonl - into csv\n",
      "Processed teacherstudentchat00138_dpo.jsonl - into csv\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'C:/Users/ariel/Documents/second_year/comp_ling/comp_ling_proj/results/test'\n",
    "output_folder = 'C:/Users/ariel/Documents/second_year/comp_ling/comp_ling_proj/results/test_processed'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def strip_emoji(text):\t\n",
    "    RE_EMOJI = re.compile(\"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return RE_EMOJI.sub(r'', text)\n",
    "\n",
    "def newline(text):\n",
    "    return re.sub(\"(\\n+)\", \". \", text)\n",
    "\n",
    "p = inflect.engine()\n",
    "def num_to_word(text):\n",
    "    #print(re.findall('\\d+', text))\n",
    "    return re.sub(r'\\d{1,8}', lambda match: p.number_to_words(match.group()), text)\n",
    "\n",
    "total_files = 0\n",
    "# Iterate over each file in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    \n",
    "    # Process only .tsv files\n",
    "    if filename.endswith('.jsonl'):\n",
    "        total_files +=1\n",
    "        num = re.search(r'\\d+', filename).group(0)\n",
    "        num = num + '.csv'\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        with open(file_path) as f:\n",
    "            lines = f.read().splitlines()\n",
    "        \n",
    "            try:\n",
    "                df_inter = pd.DataFrame(lines)\n",
    "                df_inter.columns = ['json_element']\n",
    "                df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "                df_final = df_final.drop_duplicates(subset=['prompt','original_response'])\n",
    "                #print('dropped duplicates')\n",
    "                df_final['llama_response'] = df_final['llama_response'].apply(strip_emoji)\n",
    "                #print('stripped emojies')\n",
    "                df_final['llama_response'] = df_final['llama_response'].apply(newline)\n",
    "                #print('stripped newline')\n",
    "                df_final['llama_response'] = df_final['llama_response'].apply(num_to_word)\n",
    "                #print('numbers llama')\n",
    "                df_final['original_response'] = df_final['original_response'].apply(num_to_word)\n",
    "                #print('numbers origional')\n",
    "                output_path = os.path.join(output_folder, num)\n",
    "                df_final.to_csv(output_path, index=False)\n",
    "                print(f\"Processed {filename} - into csv\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "        \n",
    "# Specify input and output folder paths\n",
    "print(total_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba0d7608-48b3-4e7a-8307-66d6b24921a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               prompt  \\\n",
      "0   The following is a conversation with a teacher...   \n",
      "1   The following is a conversation with a teacher...   \n",
      "2   The following is a conversation with a teacher...   \n",
      "3   The following is a conversation with a teacher...   \n",
      "4   The following is a conversation with a teacher...   \n",
      "..                                                ...   \n",
      "75  The following is a conversation with a teacher...   \n",
      "76  The following is a conversation with a teacher...   \n",
      "77  The following is a conversation with a teacher...   \n",
      "78  The following is a conversation with a teacher...   \n",
      "79  The following is a conversation with a teacher...   \n",
      "\n",
      "                                    original_response  \\\n",
      "0           Hi <STUDENT> , no problem! Everything OK?   \n",
      "1                           respond better than react   \n",
      "2   ok well hopefully it'll be good enough - we'll...   \n",
      "3   so, did you have time to write any examples of...   \n",
      "4        ok that's fine - can you show me an example?   \n",
      "..                                                ...   \n",
      "75  but i've just realied that confusingly - in th...   \n",
      "76  yes good - 'concentrated' is for e.g. intensit...   \n",
      "77                                    or e.g. flavour   \n",
      "78  ok no problem - thanks <STUDENT> - we'll finis...   \n",
      "79                  ok great - speak to you then.....   \n",
      "\n",
      "                                       llama_response  \n",
      "0   The following is a conversation with a teacher...  \n",
      "1   The following is a conversation with a teacher...  \n",
      "2   The following is a conversation with a teacher...  \n",
      "3   ?\\n\\nStudent: I did\\nTeacher: great - we'll ta...  \n",
      "4   !\\nStudent: I'll try to find it but it's on my...  \n",
      "..                                                ...  \n",
      "75  Student: but i guess you're right! \\nTeacher: ...  \n",
      "76  !\\nStudent: I continue with number 6, I'm not ...  \n",
      "77  ?\\n\\nStudent: Hmm\\nTeacher: or e.g. 'diluted' ...  \n",
      "78  Question: 5d - what do you think?\\n\\nStudent: ...  \n",
      "79  <END_OF_CONVERSATION>\\n\\nPlease do not use thi...  \n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#https://sundararamanp.medium.com/a-relatively-faster-approach-for-reading-json-lines-file-into-pandas-dataframe-90b57353fd38\n",
    "\n",
    "with open(input_file) as f:\n",
    "    lines = f.read().splitlines()\n",
    "df_inter = pd.DataFrame(lines)\n",
    "df_inter.columns = ['json_element']\n",
    "df_final = pd.json_normalize(df_inter['json_element'].apply(json.loads))\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59cc46c1-a717-47c7-91d3-de4c6859385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('test_df_251.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9a24dfa-0276-4994-95ae-0e18fcabac0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85808d9b-d08c-4344-8c15-46a486b4c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'teacherstudentchat00251_dpo.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d85ab99-2182-4749-95cf-5d290c3541f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00251\n"
     ]
    }
   ],
   "source": [
    "num = re.search(r'\\d+', filename).group(0)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adeb23-0905-48ef-97b1-3cddbf5355b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so here's the plan\n",
    "#first thing is to remove every other line\n",
    "#then I need to look through the llama responses for a bit\n",
    "#then see if we can isloate the parts where its \"/nTeacher\"\n",
    "#Or do we just keep its janky response?\n",
    "#then we get some flesch kincaid numbers and maybe some others\n",
    "#Then look though pre-built dpo datasets and get soem numbers\n",
    "#then we add it to one massive csv for later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad8d9ac-f750-4d64-b1f5-6eabd4836f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been merged into C:/Users/ariel/Documents/second_year/comp_ling/comp_ling_proj/results/test_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the folder containing the CSV files\n",
    "folder_path = 'C:/Users/ariel/Documents/second_year/comp_ling/comp_ling_proj/results/test_processed'\n",
    "output_path = 'C:/Users/ariel/Documents/second_year/comp_ling/comp_ling_proj/results/test_processed.csv'\n",
    "#output_file = 'merged_output.csv'\n",
    "\n",
    "# Use glob to get all CSV files in the folder\n",
    "all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Create an empty list to hold each DataFrame\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the list of files and read each one\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"All CSV files have been merged into {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfde67e8-a5dc-4d90-af27-c86e3ace8f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>original_response</th>\n",
       "      <th>llama_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following is a conversation with a teacher...</td>\n",
       "      <td>Hi there - good to speak to you!</td>\n",
       "      <td>I'm in the middle of a lecture but I'll be bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The following is a conversation with a teacher...</td>\n",
       "      <td>OK yes I can imagine! It's pretty cold here in...</td>\n",
       "      <td>I've been to Spain before and I really liked i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The following is a conversation with a teacher...</td>\n",
       "      <td>What's your normal work?</td>\n",
       "      <td>I guess you're a teacher?. Student: Yes, I'm a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following is a conversation with a teacher...</td>\n",
       "      <td>Ah right - yes I thought you seemed very fluen...</td>\n",
       "      <td>- I think I've been to Spain before so I know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The following is a conversation with a teacher...</td>\n",
       "      <td>It's careers!</td>\n",
       "      <td>I'm sorry!. Student: I got into a career in te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  The following is a conversation with a teacher...   \n",
       "1  The following is a conversation with a teacher...   \n",
       "2  The following is a conversation with a teacher...   \n",
       "3  The following is a conversation with a teacher...   \n",
       "4  The following is a conversation with a teacher...   \n",
       "\n",
       "                                   original_response  \\\n",
       "0                   Hi there - good to speak to you!   \n",
       "1  OK yes I can imagine! It's pretty cold here in...   \n",
       "2                           What's your normal work?   \n",
       "3  Ah right - yes I thought you seemed very fluen...   \n",
       "4                                      It's careers!   \n",
       "\n",
       "                                      llama_response  \n",
       "0  I'm in the middle of a lecture but I'll be bac...  \n",
       "1  I've been to Spain before and I really liked i...  \n",
       "2  I guess you're a teacher?. Student: Yes, I'm a...  \n",
       "3  - I think I've been to Spain before so I know ...  \n",
       "4  I'm sorry!. Student: I got into a career in te...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c808dce-ce92-4bcd-9b06-01bc7c3b09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top = pd.read_csv('dev_processed.csv')\n",
    "df_bottom = pd.read_csv('processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6b5e3d-a8af-4fc8-b9ae-fb4d4cd09db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13139, 3)\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.concat([df_top, df_bottom], ignore_index=True, axis=0)\n",
    "output_path = 'C:/Users/ariel/Documents/second_year/comp_ling/comp_ling_proj/results/large_processed.csv'\n",
    "print(df_merged.shape)\n",
    "df_merged.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf058c6-b82e-45aa-a73e-5adcf0d83466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f4bcc-666c-493b-919c-faba8df49b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
